{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping with Pagination\n",
    "\n",
    "You were asked to web scrape the url https://venturebeat.com. Applying what we learned so far, this should be straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. GET THE HTML CONTENT OF THE MAIN PAGE\n",
    "def geturlhtml(main_url):\n",
    "    \n",
    "    # make HTTP request\n",
    "    r = requests.get(main_url)\n",
    "    html_content = r.text\n",
    "\n",
    "    # if the request went through and we have some text, \n",
    "    # convert to beautiful object\n",
    "    if html_content is not None:\n",
    "        html_soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    else:\n",
    "        raise Exception('Error getting data from {}'.format(url))\n",
    "        \n",
    "    return html_soup\n",
    "\n",
    "# 2. FROM THE HTML CONTENT OF THE MAIN PAGE GET THE ARTICLE LINKS\n",
    "\n",
    "def featuredlinks(main_htmldoc):\n",
    "    featured = main_htmldoc.find('div', class_='FeaturedArticles')\n",
    "    return [ i['href'] for i in featured.find_all('a') ]\n",
    "\n",
    "def getarticlelinks(html_doc):\n",
    "    \n",
    "    article_links = []\n",
    "    links = html_doc.find_all('a', class_='ArticleListing__title-link')\n",
    "    for i in links:\n",
    "        article_links.append(i['href'])\n",
    "#     print(len(links))\n",
    "    return article_links\n",
    "\n",
    "\n",
    "# 3. GET THE HTML CONTENT FOR EACH ARTICLE LINK AND GET THE ARTICLE TITLE AND TEXT\n",
    "def gettextfromarticleurl(article_url):\n",
    "    \n",
    "    # new requests to individual article pages\n",
    "    r = requests.get(article_url)\n",
    "    html_content = r.text\n",
    "    \n",
    "    # convert to beautiful soup object\n",
    "    if html_content is not None:\n",
    "        html_soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    else:\n",
    "        raise Exception('Error getting data from {}'.format(url))\n",
    "    \n",
    "#     # grab the category\n",
    "#     cat_class = 'Label Label--single Label--brand Label__link--brand'\n",
    "#     article_category = html_soup.find(class_=cat_class).text.strip()\n",
    "                                      \n",
    "    # grab the title\n",
    "    article_title = html_soup.find('h1', class_='article-title').text\n",
    "    \n",
    "    # grab the body\n",
    "    articlecontent = html_soup.find(class_= 'article-content')\n",
    "    article_text = []\n",
    "    for i in articlecontent.find_all('p', recursive=False):\n",
    "        article_text.append(i.text.strip())\n",
    "    article_text = \" \".join(article_text)\n",
    "    \n",
    "    return article_title, article_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How Merck works with Seeqc to cut through quantum computing hype\n",
      "Amazon releases DeepRacer software in open source\n",
      "Campfire raises $8 million to advance AR/VR for product design\n",
      "CloudCheckr survey says cloud computing adoption is accelerating\n",
      "Atlassian’s Jira Work Management encourages team collaboration\n",
      "Gartner says low-code, RPA, and AI driving growth in ‘hyperautomation’\n",
      "Saas provider BoostUp.ai nabs $6M to support revenue operations\n",
      "DevOps orchestration platform Opsera raises $15M\n",
      "AI-powered construction project platform OpenSpace nabs $55M\n",
      "Viso Trust assesses third-party cybersecurity risk with AI, raises $3M\n",
      "MessageBird acquires email data platform SparkPost, closes $1B round\n",
      "Secrets management and authentication platform Akeyless raises $14M\n",
      "Accenture says IT investments are bearing fruit\n",
      "Salesforce launches employee upskilling toolkit for businesses\n",
      "Sysdig raises $189M to monitor containers and apps in the cloud\n",
      "AMD bets on strong demand for chips as revenue soars 93%\n",
      "Microsoft beats Q3 revenue expectations, spurred by strong cloud sales\n",
      "Formation launches AI-driven sales offer optimization platform\n",
      "Pricefx launches AI-powered market simulation tool\n",
      "Red Hat open-sources TrustyAI, an auditing tool for AI decision systems\n",
      "Open source AI stack is ready for its moment\n",
      "Amazon releases DeepRacer software in open source\n",
      "Red Hat touts safety in future Linux OS for cars\n",
      "Cigent Technology melds security and storage to protect sensitive data\n",
      "2nd Watch: Most enterprises lack in-house skills for data strategy\n",
      "How Merck works with Seeqc to cut through quantum computing hype\n",
      "Legal management startup Clio nabs $110M to expand its platform\n",
      "Automated contract negotiation platform Pactum raises $11M\n",
      "Arm’s Neoverse server chips generate at least 40% better performance\n",
      "Campfire raises $8 million to advance AR/VR for product design\n",
      "Rewind extends SaaS data backup and recovery to Trello\n",
      "Adobe extends AI-infused customer analytics platform to offline data\n",
      "Automox raises $110M to help enterprises manage endpoints\n",
      "Databook raises $16M to automate key sales processes\n",
      "Zoom brings Alexa for Business to conference room calls\n",
      "Earthquake-monitoring platform Safehub raises $9M\n",
      "HashiCorp revoked private key exposed in Codecov security breach\n",
      "Apple will focus on machine learning, AI jobs in new NC campus\n",
      "Apple’s new iPhone privacy changes, explained\n",
      "Toyota subsidiary acquires Lyft self-driving division for $550M\n",
      "IoT development platform Prescient Devices nabs $2M\n",
      "Network security company Proofpoint goes private in $12.3B deal\n",
      "Zoom launches Immersive View to unify participants in the same virtual room\n"
     ]
    }
   ],
   "source": [
    "url = 'https://venturebeat.com'\n",
    "\n",
    "# 1. GET THE HTML CONTENT OF THE MAIN PAGE\n",
    "html_soup = geturlhtml(url)\n",
    "\n",
    "# 2. FROM THE HTML CONTENT OF THE MAIN PAGE GET THE ARTICLE LINKS\n",
    "article_links = featuredlinks(html_soup) + getarticlelinks(html_soup)\n",
    "\n",
    "# 3. GET THE HTML CONTENT FOR EACH ARTICLE LINK AND GET THE ARTICLE TITLE AND TEXT\n",
    "data = [gettextfromarticleurl(i) for i in article_links]\n",
    "article_titles = [i for (i,j) in data]\n",
    "article_texts = [j for (i,j) in data]\n",
    "for i in article_titles:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(article_titles))\n",
    "print(len(article_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Pagination\n",
    "\n",
    "Pagination is a technique in webdesigning that splits content into various pages, thus presenting large datasets in digestible manner for web users. There are many pagination methods:\n",
    "- numbered pagination\n",
    "- infinite scrolling\n",
    "- next button\n",
    "- load more buttons, etc. \n",
    "\n",
    "While pagination makes web browsing experience better, it certainly makes the task of web scrapping more difficult. \n",
    "\n",
    "Let's see an example now. The webpage we are looking to scrape is https://venturebeat.com. When you scroll to the bottom of the page, you will notice that at some point the url changes to https://venturebeat.com/page/2/ and this pattern continues. \n",
    "\n",
    "So, lets repeat what we did above for the url page 2 and see if we get new article links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 article urls to retrieve.\n",
      "Text retrieved for 83 articles\n"
     ]
    }
   ],
   "source": [
    "# 1. GET THE LIST OF WEBPAGES TO SCRAPE\n",
    "web_urls = ['https://venturebeat.com', 'https://venturebeat.com/page/2']\n",
    "\n",
    "# 2. FOR EACH WEBPAGE GET THE ARTICLE LINKS\n",
    "n_urls = len(web_urls)\n",
    "all_urls = []\n",
    "\n",
    "for i in range(0,n_urls):\n",
    "    html_soup = geturlhtml(web_urls[i])\n",
    "    if i == 0:\n",
    "        all_urls.extend( featuredlinks(html_soup) + getarticlelinks(html_soup) )\n",
    "    else:\n",
    "        all_urls.extend( getarticlelinks(html_soup) )\n",
    "print(f'There are {len(all_urls)} article urls to retrieve.')\n",
    "\n",
    "# 3. FOR EACH ARTICLE LINK GET THE HTML CONTENT - TITLE AND TEXT\n",
    "data = [gettextfromarticleurl(i) for i in all_urls]\n",
    "article_titles = [i for (i,j) in data]\n",
    "article_texts = [j for (i,j) in data]\n",
    "\n",
    "print(f'Text retrieved for {len(article_texts)} articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can expand the webpages urls easily, simply collect a number of webpages using page numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://venturebeat.com', 'https://venturebeat.com/page/2', 'https://venturebeat.com/page/3', 'https://venturebeat.com/page/4', 'https://venturebeat.com/page/5', 'https://venturebeat.com/page/6', 'https://venturebeat.com/page/7', 'https://venturebeat.com/page/8', 'https://venturebeat.com/page/9', 'https://venturebeat.com/page/10', 'https://venturebeat.com/page/11', 'https://venturebeat.com/page/12', 'https://venturebeat.com/page/13', 'https://venturebeat.com/page/14']\n"
     ]
    }
   ],
   "source": [
    "# 1. GET THE LIST OF WEBPAGES\n",
    "web_urls = ['https://venturebeat.com']\n",
    "\n",
    "page_no = range(2,15,1)\n",
    "for i in page_no:\n",
    "    web_urls.append('https://venturebeat.com/page/'+str(i))\n",
    "print(web_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 563 article urls to retrieve.\n",
      "Text retrieved for 563 articles\n"
     ]
    }
   ],
   "source": [
    "# 2. FOR EACH WEBPAGE GET THE ARTICLE LINKS\n",
    "n_urls = len(web_urls)\n",
    "all_urls = []\n",
    "\n",
    "for i in range(0,n_urls):\n",
    "    html_soup = geturlhtml(web_urls[i])\n",
    "    if i == 0:\n",
    "        all_urls.extend( featuredlinks(html_soup) + getarticlelinks(html_soup) )\n",
    "    else:\n",
    "        all_urls.extend( getarticlelinks(html_soup) )\n",
    "print(f'There are {len(all_urls)} article urls to retrieve.')\n",
    "\n",
    "# 3. FOR EACH ARTICLE LINK GET THE HTML CONTENT - TITLE AND TEXT\n",
    "data = [gettextfromarticleurl(i) for i in all_urls]\n",
    "article_titles = [i for (i,j) in data]\n",
    "article_texts = [j for (i,j) in data]\n",
    "\n",
    "print(f'Text retrieved for {len(article_texts)} articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed  1  files\n",
      "processed  2  files\n",
      "processed  3  files\n",
      "processed  4  files\n",
      "processed  5  files\n",
      "processed  6  files\n",
      "processed  7  files\n",
      "processed  8  files\n",
      "processed  9  files\n",
      "processed  10  files\n",
      "processed  11  files\n",
      "processed  12  files\n",
      "processed  13  files\n",
      "processed  14  files\n",
      "processed  15  files\n",
      "processed  16  files\n",
      "processed  17  files\n",
      "processed  18  files\n",
      "processed  19  files\n",
      "processed  20  files\n",
      "processed  21  files\n",
      "processed  22  files\n",
      "processed  23  files\n",
      "processed  24  files\n",
      "processed  25  files\n",
      "processed  26  files\n",
      "processed  27  files\n",
      "processed  28  files\n",
      "processed  29  files\n",
      "processed  30  files\n",
      "processed  31  files\n",
      "processed  32  files\n",
      "processed  33  files\n",
      "processed  34  files\n",
      "processed  35  files\n",
      "processed  36  files\n",
      "processed  37  files\n",
      "processed  38  files\n",
      "processed  39  files\n",
      "processed  40  files\n",
      "processed  41  files\n",
      "processed  42  files\n",
      "processed  43  files\n",
      "no of webpages to scrape:  14\n",
      "total no. of article links:  43\n",
      "total no. of article titles and texts:  (43, 43)\n"
     ]
    }
   ],
   "source": [
    "# 4. CONVERT DATA TO DICTIONARY\n",
    "\n",
    "data_dictionary = {'url':[], 'title':[], 'text':[]}\n",
    "tracker = 0\n",
    "for i in article_links:\n",
    "    title, text = gettextfromarticleurl(i)\n",
    "    data_dictionary['url'].append(i)\n",
    "    data_dictionary['title'].append(title)\n",
    "    data_dictionary['text'].append(text)\n",
    "    tracker += 1\n",
    "    print('processed ', tracker, ' files')\n",
    "    \n",
    "print('no of webpages to scrape: ', N)\n",
    "print('total no. of article links: ', len(article_links))\n",
    "print('total no. of article titles and texts: ', (len(data_dictionary['title']), \n",
    "                                                  len(data_dictionary['text'])) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://venturebeat.com/2021/04/27/how-merck-w...</td>\n",
       "      <td>How Merck works with Seeqc to cut through quan...</td>\n",
       "      <td>When it comes to grappling with the future of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://venturebeat.com/2021/04/27/amazon-make...</td>\n",
       "      <td>Amazon releases DeepRacer software in open source</td>\n",
       "      <td>In November 2018, Amazon launched AWS DeepRace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://venturebeat.com/2021/04/27/campfire-ra...</td>\n",
       "      <td>Campfire raises $8 million to advance AR/VR fo...</td>\n",
       "      <td>Campfire has raised $8 million in funding for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://venturebeat.com/2021/04/28/cloudcheckr...</td>\n",
       "      <td>CloudCheckr survey says cloud computing adopti...</td>\n",
       "      <td>Cloud transformation is moving quickly, accord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://venturebeat.com/2021/04/28/atlassians-...</td>\n",
       "      <td>Atlassian’s Jira Work Management encourages te...</td>\n",
       "      <td>At its Team21 conference today, Atlassian unve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://venturebeat.com/2021/04/27/how-merck-w...   \n",
       "1  https://venturebeat.com/2021/04/27/amazon-make...   \n",
       "2  https://venturebeat.com/2021/04/27/campfire-ra...   \n",
       "3  https://venturebeat.com/2021/04/28/cloudcheckr...   \n",
       "4  https://venturebeat.com/2021/04/28/atlassians-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  How Merck works with Seeqc to cut through quan...   \n",
       "1  Amazon releases DeepRacer software in open source   \n",
       "2  Campfire raises $8 million to advance AR/VR fo...   \n",
       "3  CloudCheckr survey says cloud computing adopti...   \n",
       "4  Atlassian’s Jira Work Management encourages te...   \n",
       "\n",
       "                                                text  \n",
       "0  When it comes to grappling with the future of ...  \n",
       "1  In November 2018, Amazon launched AWS DeepRace...  \n",
       "2  Campfire has raised $8 million in funding for ...  \n",
       "3  Cloud transformation is moving quickly, accord...  \n",
       "4  At its Team21 conference today, Atlassian unve...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT DICTIONARY TO DATAFRAME\n",
    "df = pd.DataFrame.from_dict(data_dictionary)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://venturebeat.com/2021/04/27/how-merck-works-with-seeqc-to-cut-through-quantum-computing-hype/'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How Merck works with Seeqc to cut through quantum computing hype'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When it comes to grappling with the future of quantum computing, enterprises are scrambling to figure just how seriously they should take this new computing architecture. Many executives are trapped between the anxiety of missing the next wave of innovation and the fear of being played for suckers by people overhyping quantum’s revolutionary potential. That’s why the approach to quantum by pharmaceutical giant Merck offers a clear-eyed roadmap for other enterprises to follow. The company is taking a cautious but informed approach that includes setting up an internal working group and partnering with quantum startup Seeqc to monitor developments while keeping an open mind. According to Philipp Harbach, a theoretical chemist who is head of Merck’s In Silico Research group, a big part of the challenge remains trying to keep expectations of executives reasonable even as startup funding to quantum soars and the hype continues to mount. “We are not evangelists of quantum computers,” Harbach said. “But we are also not skeptics. We are just realistic. If you talk to academics, they tell you there is no commercial value. And if you talk to our management, they tell you in 3 years they want a product out of it. So, there are two worlds colliding that are not very compatible. I think that’s typical for every hype cycle.” Merck’s desire for the dream of quantum computing to become reality is understandable. The fundamental nature of its business — biology and chemistry — means the company has been building molecular or “quantum” level models for more than a century. Part of the role of the In Silico Research group is to develop those models that can solve quantum problems using evolving technologies such as data analytics and AI and applying them to natural sciences to make experimental work less time-consuming. But those models are always limited and imperfect because they are being calculated on non-quantum platforms that can’t fully mimic the complexity of interactions. If someone can build a fully fault-tolerant quantum computer that operates at sufficient scale and cost, Merck could unlock a new generation of efficiencies and scientific breakthroughs. “The quantum computer will be another augmentation to a classical computer,” Harbach said. “It won’t be a replacement, but an augmentation which will tackle some of these problems in a way that we cannot imagine. Hopefully, it will speed them up in a way that the efficacy of the methods we are employing will be boosted.” About 3 years ago, Merck decided it was time to start educating itself about the emerging quantum sector. The company’s venture capital arm, M Ventures, began looking within the company for experts who could help it with due diligence as it began to assess quantum startups. That included mapping out the players and the whole value chain of quantum computing, according to Harbach. That led to the formal creation of the Quantum Computing Task Force, which has roughly 50 members who try to communicate with quantum players large and small as well as peers among Merck’s own competition. “We are basically an interest group trying to understand this topic,” Harbach said. “That’s why we have a quite good overview and understanding on timelines, player possibilities, and applications.” As part of that exploration, M Ventures eventually began investing in quantum-related startups. In April 2020, the venture fund announced a $5 million investment in Seeqc, a New York-based startup that bills itself as the “Digital Quantum Computing” company. “We thought that it might be good to have partners in the hardware part and in the software part,” Harbach said. “Seeqc will partner with us within Merck to really work on problems basically as a hardware partner.” Seeqc is developing a hybrid approach that it believes will make quantum computing useful sooner. The idea is to combine classical computing architectures with quantum computing. It does this through its system-on-a-chip design. This technology was originally developed at Hypres, a semiconductor electronics developer which spun out Seeqc last year. The M Ventures funding for Seeqc followed a previous $6.8 million seed round. Seeqc raised a subsequent round of $22 million last September in a round led by EQT Ventures. According to Seeqc CEO John Levy, the company’s technology allows it to address some of the fundamental challenges facing quantum systems. Despite rapid advancements in recent years, quantum computers remain too unstable to deliver the high-performance computing needed to justify their costs. Part of the reason for that is that qubits, the unit of quantum computing power, need to be kept at near-freezing temperatures to process. Scaling then becomes costly and difficult because a system operating with thousands of qubits would be immensely complex to manage, in part because of the massive heating issue. Levy said Seeqc can address that problem by placing classic microchips over a qubit array to stabilize the environment at cryogenic temperatures while maintaining speed and reducing latency. The company uses a single-flux quantum technology that it has developed and that replaces the microwave pulses being used in other quantum systems. As a result, the company says its platform enables quantum computing at about 1/400 of the cost of current systems in development. “We have taken much of the complexity that you’ve seen in a quantum computer and we’ve removed almost all of that by building a set of chips that we’ve designed,” Levy said. Just as important is a philosophical approach Seeqc is taking. It’s not building a general-purpose quantum computer. Instead, it plans to build application-specific ones that are tailored specifically to the problems a client is trying to solve. Because Seeqc has its own chip foundry, it can customize its chips to the needs of application developers as they create different algorithms, Levy said. In that spirit, Merck’s Quantum Computing Task Force is working closely with Seeqc to create viable quantum computers that can be used by its various businesses. “Their technology is a key technology to scale a quantum computer, which is actually much more important because it will make quantum computers bigger and cheaper,” Harbach said. “And this is, of course, essential for the whole market.” For all this activity, Harbach’s view of quantum’s potential remains sober. He sees nothing on the market that will have any commercial impact, certainly not for Merck. At this point, many of the company’s questions remain academic. “What we are basically interested in is how — or will — the quantum computer hardware ever be scalable to a level that it can tackle problems of realistic size to us,” Harbach said. “And the same question also goes to the software side. Will there ever be algorithms that can basically mimic these problems on a quantum computer efficiently so that they don’t run into noise problems? We are not interested in simulating a molecule right now on a quantum computer. Everything we try to understand is about the timelines: What will be possible and when will it possible.” Harbach has watched the rise in quantum startup funding and various milestone announcements but remains dubious of many of these claims. “They are creating a new market where there’s not even the technology ready for it,” Harbach said. “You have to stay realistic. There’s a lot of money at the moment from governments and VCs. There’s a lot of boost from consultancies because they try to sell the consultancy. And if you talk to experts, it’s the other way around. They tell you not before 15 years.” The questions Merck asks internally are split into 2 fundamental categories: When will there be a quantum computer that can be more efficient at processing its current quantum models? And when will there be a quantum computer that is so powerful that it opens up new problems and new solutions that the company cannot even imagine today? “Quantum will be a thing, definitely,” Harbach said. “The only question is when, and I’m really, really sure it won’t be in the next two years. I wouldn’t even say three years. There will be a quantum winter. Winter is coming.”'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43 entries, 0 to 42\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   url     43 non-null     object\n",
      " 1   title   43 non-null     object\n",
      " 2   text    43 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('venturebeat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
